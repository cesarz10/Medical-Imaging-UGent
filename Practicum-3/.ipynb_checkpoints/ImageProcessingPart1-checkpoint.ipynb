{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Medical Imaging \n",
    "##  Practical session 3\n",
    "### Image Processing: Image Enhancement and Filtering\n",
    "### 14th November 2023\n",
    "***\n",
    "**Sebastian Amador Sanchez (sebastian.amador.sanchez@vub.be), Jef Vandemeulebroucke\\\n",
    "Department of Electronics and Informatics (ETRO)\\\n",
    "Vrije Universitet Brussel, Pleinlaan 2, B-1050 Brussels, Belgium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "The jupyter notebook should be submitted as the report by teams of two using the assignment functionality of Ufora.\n",
    "\n",
    "Please complete this notebook and upload the following before the deadline **November 27, 2023, at 23:59**:\n",
    "- the notebook in *.ipynb* format\n",
    "- the executed notebook in *.html* format (File --> Download As --> HTML)\n",
    "\n",
    "The report should contain concise answers to the questions (in specified cells), python code and plotted figures. For this practical session, **we do not** require a separate written report in *.pdf* format.\n",
    "\n",
    "## Introduction\n",
    "This exercise session aims to gain insight into the image enhancement and filtering operations commonly applied in medical image processing. You are expected to obtain enhanced and noise-free images at the end of this session.\n",
    "\n",
    "For more information on the following concepts, see the lecture recordings, course slides, and the related study material.\n",
    "\n",
    "\n",
    "### BraTS dataset\n",
    "You will be working with images from the [*Brain Tumor Segmentation (BRATS) Challenge*](http://www.braintumorsegmentation.org), which contains scans of multiple glioma cases. Gliomas are a type of brain tumor originating in the glial cells surrounding the neurons. They are characterized by having various heterogeneous histological subregions. Therefore, they have varying intensity profiles, and multimodal MRI scans must be employed to visualize them properly.\n",
    "\n",
    "<img src=\"./images/brats.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "**(A)** Whole tumor visible in T2-FLAIR **(B)** Tumor core visible in T2 **(C)** Tumor (blue) and necrotic component (green) visible in T1-Contrast **(D)** Tumor sub-regions.\n",
    "\n",
    "You DO NOT have to download the dataset; the images that you will employ are included in this practical session. These images were artificially corrupted so that you can apply enhancing and denoising techniques.\n",
    "\n",
    "\n",
    "#### Questions:  [sebastian.amador.sanchez@vub.be](mailto:sebastian.amador.sanchez@vub.be)\n",
    "\n",
    "### Required modules\n",
    "Before starting make sure you have installed the following libraries:\n",
    "\n",
    "- ```SimpleITK``` -> Read and write images\n",
    "- ```numpy``` -> Operation with arrays\n",
    "- ```matplotlib``` -> Plot images\n",
    "- ```skimage``` -> Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image Enhancement\n",
    "## 1.1 The image histogram\n",
    "The histogram represents how many pixels have a certain intensity in the corresponding image. In image processing, it facilitates the identification of image acquisition issues, for example:\n",
    "\n",
    "- **Over and under exposure:** Are intensity values spread out (good) or clustered (bad)?\n",
    "\n",
    "<img src=\"./images/hist_exposure.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "- **Contrast:** In the image, are there many distinct intensity values (high contrast), or does the image use few intensity values (low contrast)? A \"normal\" contrast is when intensity values are widely spread, with a significant difference between min and max intensity values. \n",
    "\n",
    "<img src=\"./images/hist_contrast.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "- **Dynamic range:** Related to the number of distinct pixels in the image.\n",
    "\n",
    "<img src=\"./images/hist_dyn_range.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Unlike previous examples, medical images can have a large intensity range or even floating point intensities. This yields very large histograms and makes the pixel count per intensity impractical.\n",
    "\n",
    "<img src=\"./images/hist_mri.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Therefore, in practice intensities are usually binned, i.e. grouped in a reduced number of bins with similar intensity.\n",
    "\n",
    "## 1.2 Image enhancement\n",
    "\n",
    "We shall discuss three ways of contrast improvement: \n",
    "\n",
    "1. [Linear contrast mapping](http://homepages.inf.ed.ac.uk/rbf/HIPR2/stretch.htm) or histogram stretching. It involves a linear transformation on the image intensities, such that the transformed intensities cover to the full range.\n",
    "2. [Histogram equalisation](https://homepages.inf.ed.ac.uk/rbf/HIPR2/histeq.htm). In this case, the aim is to obtain a uniform histogram, in which all intensities are equally represented. This can be done by applying a nonlinear transformation on the image intensities.\n",
    "3. [CLAHE](https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html). Contrast Limiting Adaptive Histogram Enhancement (CLAHE) solves the resultant noise from applying histogram equalization. Instead of executing the equalization in a \"global\" manner, CLAHE applies histogram equalization in small patches taken from the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.\n",
    "- Start by reading the image \"T1.mha\" from the folder \"MRI_images\" with the command [```ReadImage(path_to_image)```](https://simpleitk.readthedocs.io/en/master/IO.html). ```SimpleITK``` returns an ITK image that you will have to convert to an array before using any other non SimpleITK related python functions; for example, ```plt.imshow(image)``` or ```plt.hist(image, bins)```.\n",
    "- To visualize the image, first convert it to an array using ```sitk.GetArrayFromImage(image)```. Next, employ [```plt.imshow(array)```](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html) to show the image. \n",
    "- Afterwards, use [```plt.hist(image, bins)```](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html) from ```matplotlib``` with ```bins='auto'``` to view the histogram. \n",
    "\n",
    "\n",
    "### Exercise 1.1: Linear contrast mapping\n",
    "Write a function that performs linear histogram stretching (see course slides) between 0 and 1. Look at the result and its histogram with bins set to ```auto```. Compare with the histogram of the original. To built the function:\n",
    "1. Instead of using the minimum and maximum intensity values of the image, employ the P5 and P95 percentiles of the image array using [```np.percentile```](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html).\n",
    "2. Use [```np.clip```](https://numpy.org/doc/stable/reference/generated/numpy.clip.html) to limit the image intensities between the P5 and P95 percentiles.\n",
    "3. Apply the linear stretching transformation to the clip image using the percentile values as min and max intensities (P5 and P95 respectively).\n",
    "\n",
    "\n",
    "### Exercise 1.2: Histogram equalization\n",
    "Implement histogram equalization to the original image. Compare your resultant image with the one obtained by using [CLAHE](https://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.equalize_adapthist). To create the equalized histogram:\n",
    "1. Get the original histogram and the respective bin edges employing ```np.histogram``` and a number of bins equal to 64. You will have to apply ```.ravel()``` to the image array to correctly obtain the values.\n",
    "2. Calculate the center of the bin edges.\n",
    "3. Determine the cumulative histogram using [```.cumsum()```](https://numpy.org/devdocs/reference/generated/numpy.cumsum.html)\n",
    "4. Re-scale the cumulative histogram between 0 and 1 by dividing with the max value of the cumulative histogram.\n",
    "5. Use [```np.interp()```](https://numpy.org/doc/stable/reference/generated/numpy.interp.html) to map the original pixel values to their new distribution. Since ```np.interp()``` is a one-dimensional linear interpolation, flat the original image array using [```flat```](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flat.html).  Additionally, use the center of the bin edges as the x-coordinates and the re-scaled cumulative histogram as the y-coordinates.\n",
    "6. Since the output of point 5 is a 1D-array, reshape it to the original size using [```.reshape(shape)```](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
    "\n",
    "\n",
    "## Report\n",
    "<font color=blue>\n",
    "\n",
    "- Show a four-by-two image comparison (use ```subplots```). Display the original MRI image, the linear stretched, the histogram equalized, the CLAHE, and their corresponding histograms.\n",
    "- In the linear constrast mapping step we have introduced lower and upper intensity percentiles. What is the reason for that?\n",
    "- Look at the output results and their histograms. Compare them with the histogram of the original input image. The histogram of the histogram-equalized output image is not perfectly uniform. What is the reason for this?\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image Denoising\n",
    "\n",
    "Acquiring an image is always prone to artifacts that may corrupt or degrade its quality. Examples of them are noise, blurring, and distortion. Multiple image restoration filters have been proposed in medical imaging to reduce the effect of these artifacts. Image filters may be used either to improve the image quality before reviewing it or as a pre-processing step to improve the result of further image processing operations such as segmentation.\n",
    "\n",
    "<img src=\"./images/denoising.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "## 2.1 Noise suppression.\n",
    "\n",
    "Image noise can often be assumed to be a high-frequency signal. Therefore, many noise reduction approaches filter the high-frequency components while preserving the low-frequency ones; a typical example is the 2D-Gaussian filter.\n",
    "\n",
    "Despite the wide use of low-pass filtering, this technique has the side effect of blurring the edges of the image. To avoid it, smoothing filters that preserve the edges, such as the non-linear median filter, have been proposed.\n",
    "\n",
    "<img src=\"./images/noise_removal.png\" alt=\"drawing\" width=\"700\"/>\n",
    "\n",
    "## 2.2 Edge enhancement\n",
    "The goal is to enhance the edge contrast of an image in an attempt to improve its apparent sharpness. The resultant edge-image can be added to the original image to enhance the visual quality or be employed as input in an image segmentation approach. \n",
    "\n",
    "<img src=\"./images/edge_enhancement.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "To illustrate image filtering, you will restore an image which has been distorted with \"Salt and Pepper\" noise.\n",
    "\n",
    "1. Read the ground truth image 'T2.mha' and its noisy version 'SP.mha'.\n",
    "2. Apply [Gaussian filtering](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html) to the noisy image with a standard deviation of 1.\n",
    "3. Calculate the filtered and the remaining noise.\n",
    "4. Calculate the root mean squared error ([RMSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)) between the obtained filtered image and the ground truth.\n",
    "5. Create an edge map of the obtained filtered image using the [prewitt function](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.prewitt).\n",
    "6. Repeat steps 3 to 5 using:\n",
    "  - A [median filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.median_filter.html) with a kernel of size 3. \n",
    "  - A mean filter with a kernel of size 3 x 3. Use [```np.ones```](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) to create your kernel, and [ndimage.convolve](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve) to apply the kernel to the image.\n",
    "\n",
    "**hint:** ```RMSE = sqrt(MSE)```\n",
    "\n",
    "## Report\n",
    "<font color=blue>\n",
    "    \n",
    "- Show a three-by-four plot that displays the following for each method: the resultant filtered image, the filtered noise, the noise that remained and the edge map of the filtered image.     \n",
    "- Provide all three values for the RMSE between filtered image and the ground truth. Comment briefly on the results.\n",
    "- What is the interpretation of the difference image with the ground truth and the difference image with the original input image?\n",
    "- Which filter works best in terms of RMSE and why?\n",
    "- Which filter preserves the edges the best?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Intensity non-uniformity correction\n",
    "\n",
    "Non-uniform intensity correction is another common task in image denoising. Grayscale inhomogeneities appear in magnetic resonance (MR) images as systematic changes in the local statistical characteristics of tissues. Homomorphic Unsharp Masking (HUM) is applied as a post-processing tool to reduce these intensity effects.\n",
    "\n",
    "HUM is conceptually straightforward; it can be easily implemented and is very fast. It relies on the assumption that if grayscale inhomogeneities are not present in the image, the mean or median in a local window should match the global mean or median of the overall image. This assumption is approximately true when the filter window is large enough to enclose a representative sample of tissues.\n",
    "\n",
    "For a detailed implementation see the paper: [*''Optimized Homomorphic Unsharp Masking for MR Grayscale Inhomogeneity Correction'' by Benjamin H. Brinkmann, Armando Manduca and Richard A. Robb, IEEE, 1998*](https://ieeexplore.ieee.org/document/700729)\n",
    "\n",
    "HUM requires the computation of:\n",
    "- The global mean value $\\mu$ of the corrupted image\n",
    "- The local mean values $\\mu_{i,j}$ for each pixel considering a neighbourhood\n",
    "- The HUM corrected/ideal value of a pixel is:\n",
    "\n",
    "$$f_{i,j} = g_{i,j} \\cdot \\frac{\\mu}{\\mu_{i,j}},$$ \n",
    "\n",
    "   where $g_{i,j}$ is the intensity value of the input image (corrupted/observed image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2\n",
    "\n",
    "Image 'Bias.mha' is a biased corrupted version of 'Flair.mha'. Implement the HUM algorithm in three different ways to compensate for the artifact:\n",
    "\n",
    "1. Implement the algorithm straightforwardly using a moving window of $40 \\times 40$ pixels to calculate the local mean. Because of the size of your local window, you will not be able to correct pixels close to the image borders.\n",
    "2. Involve the pixels at the image borders by prior padding the image and, thus, enlarging the image. Pad the image with zeros using half of your window size. To pad the image, use [```np.pad```](https://numpy.org/doc/stable/reference/generated/numpy.pad.html)\n",
    "3. In addition to the padding, leave out the pixels belonging to the background by using a global threshold of 10 over the complete image. In other words, do not include the pixels below the threshold in your calculation of the global mean value.\n",
    "\n",
    "We expect that for each case, you create a function that has the following backbone:\n",
    "- Calculates the global mean intensity.\n",
    "- For points 2 and 3: Before creating the template, you will have to pad the bias image with zeros using the half size of your window.\n",
    "- For point 3: Get the global mean intensity of the padded bias image by globally applying the threshold.\n",
    "- Iterate over the bias image using the window you set, and apply the HUM equation: $f_{i,j} = g_{i,j} \\cdot \\frac{\\mu}{\\mu_{i,j}}$.\n",
    "- For points 2 and 3: You will have to return to the original image size. \n",
    "\n",
    "\n",
    "After the bias field is removed, calculate the [normalized-root-mean-squared-error](https://scikit-image.org/docs/dev/api/skimage.metrics.html#skimage.metrics.normalized_root_mse) (NRMSE) and the [structural similarity index](https://scikit-image.org/docs/dev/api/skimage.metrics.html#skimage.metrics.structural_similarity)  (SSIM) to evaluate the performance of the denoising algorithms.\n",
    "\n",
    "\n",
    "**Remarks:** \n",
    "\n",
    "- Read the non-bias brain image in '```uint8```' format\n",
    "- Since you will be padding with zeros, use: $\\frac{\\mu}{\\mu_{i,j} + \\varepsilon}$, $\\varepsilon = 1^{-6}$\n",
    "- Make sure the resultant images are in '```uint8```' format\n",
    "\n",
    "## Report:\n",
    "<font color=blue>\n",
    "    \n",
    "- Plot a one-by-four figure showing the image with bias (Bias.mha) and the three corrected images obtained using the different implementations of the HUM algorithm.\n",
    "- Provide the values for the NRMSE and SSIM between the three corrected images and the ground truth (Flair.mha).\n",
    "- Which case had a better performance? Why?.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
