{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Medical Imaging \n",
    "##  Practical session 4: Image Processing - Part II \n",
    "### Image Segmentation\n",
    "###  13th December 2022\n",
    "***\n",
    "**Sebastian Amador Sanchez (sebastian.amador.sanchez@vub.be), Jakub Cerenka, Jef Vandemeulebroucke\\\n",
    "Department of Electronics and Informatics (ETRO)\\\n",
    "Vrije Universitet Brussel, Pleinlaan 2, B-1050 Brussels, Belgium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For more information on the following concepts see the lecture recordings, course slides and the related study material.\n",
    "\n",
    "### Purpose\n",
    "The goal of this exercise session is to obtain insight in the image segmentation operations and their evaluation metrics commonly applied in medical image processing.\n",
    "\n",
    "\n",
    "### BraTS dataset\n",
    "You will be working with images from the [*Brain Tumor Segmentation (BRATS) Challenge*](http://www.braintumorsegmentation.org), which contains scans of multiple glioma cases. Gliomas are a type of brain tumor originating in the glial cells surrounding the neurons. They are characterized by having various heterogeneous histological sub-regions. Therefore, they have varying intensity profiles. Consequently, multimodal MRI scans must be employed to properly visualize them, making multimodal segmentation of brain tumors a significant challenge in medical image analysis.\n",
    "\n",
    "<img src=\"./images/brats.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "**(A)** Whole tumor visible in T2-FLAIR **(B)** Tumor core visible in T2 **(C)** Enhancing tumor (blue) and necrotic component (green) visible in T1-Contrast **(D)** Tumor sub-regions.\n",
    "\n",
    "You DO NOT have to download the dataset, you have to employ the images acquired in the previous session. If you were not able to obtain them, these are provided within the files. \n",
    "\n",
    "\n",
    "### Instructions\n",
    "The jupyter notebook should be submitted as the report individually or by teams of two using the assignment functionality of Ufora.\n",
    "\n",
    "Please complete this notebook and upload the following before the deadline **27th December, 2022, at 23:59**:\n",
    "- the notebook in *.ipynb* format\n",
    "- the executed notebook in *.html* format (File --> Download As --> HTML)\n",
    "\n",
    "The report should contain concise answers to the questions (in specified cells), python code and plotted figures.\n",
    "For this practical session, we do not require a separate written report in *.pdf* format.\n",
    "\n",
    "#### Questions:  [samadors@etrovub.be](mailto:samadors@etrovub.be)\n",
    "\n",
    "### Required modules\n",
    "Before starting make sure you have installed the following libraries:\n",
    "\n",
    "- ```SimpleITK``` -> Read and write images, image operations\n",
    "- ```numpy``` -> Operation with arrays\n",
    "- ```matplotlib``` -> Plot images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image segmentation\n",
    "Image segmentation can be defined as any method that results in partitioning an image into meaningful regions. This is done by defining the boundaries of a region of interest, known as foreground, with similar characteristics, such as shape, color, or texture. The remaining image volume is known as the background.\n",
    "\n",
    "<img src=\"./images/segmentations.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "**Left:** Retinal blood vessel segmentation. **Center.** Skin cancer lesion segmentation. **Left.** CT lung segmentation.\n",
    "\n",
    "In medical imaging, segmentation is either a pre-processing step or a goal itself. For example, the qualitative 3D representation of an organ requires the accurate delineation or segmentation of that organ from the stack of images. Here the segmentation is used as preprocessing step for the visualization. In contrast, segmentation is a goal in qualitative or quantitative image analysis for specific diagnostical tasks, e.g., tumor size measurements in brain MRI or fetal head measurements in US.\n",
    "\n",
    "Many different methods exist, and the optimal choice is highly dependent on the region to be segmented and the type and quality of the image. Regardless of the imaging modality and according to the image features, two main approaches can be distinguished:\n",
    "1. **Region based:** We look for uniform regions in an image\n",
    "2. **Edge based:** We look for the boundaries between regions with different characteristics. \n",
    "\n",
    "## 1.1 Thresholding\n",
    "\n",
    "Image thresholding is the simplest and fastest segmentation method. The process comes down to defining one or more intensity boundaries in the image histogram. Pixels with intensity within the boundaries will get mapped to 1 (inside), while the others will be considered background (0). The process can be extended to multiple labels using multiple (upper and lower) boundaries.\n",
    "\n",
    "<img src=\"./images/thresholding.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "**(i)** Original image **(ii)** Image histogram **(iii)** Too high threshold **(iv)** Too low threshold **(v)** Ideal threshold\n",
    "\n",
    "Despite its simplicity, thresholding is sometimes the least accurate approach. Factors like image contrast, resolution, and objects with varying brightness levels can hamper thresholding performance.\n",
    "\n",
    "<img src=\"./images/histograms.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "**(i)** Gray-level hisotgrams approximated by two normal distributions **(ii)** Combined histograms. See third case, where to set the threshold?\n",
    "\n",
    "### Optimal thresholding\n",
    "Thresholding can be done either by manually selecting the boundaries or automatically optimizing the boundary values with respect to a specific criterion. For instance, Otsu thresholding will automatically set boundaries that maximize the between-class variance of two or more regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1:\n",
    "\n",
    "One of the first algorithms dedicated to finding an optimal threshold was the one proposed by [Otsu N](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4310076). Its most straightforward form segments the image histogram into two classes: background and foreground. In this exercise, you will apply the [extended version](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.3669&rep=rep1&type=pdf) to divide an image into multiple regions and segment a tumor from an MRI image. Additionally, you will get familiarized with post-processing techniques and segmentation evaluation metrics.\n",
    "\n",
    "1. Use ```sitk.ReadImage()``` to read both the MRI image: 'Flair_0266.mha', and the ground truth segmentation: 'Mask_0266.mha' (read the ground truth as sitk.sitkUInt8) from the folder 'MRIs266'.\n",
    "\n",
    "2. Perfom the Otsu multi-thresholding algorithm employing [```sitk.OtsuMultipleThresholdsImageFilter```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1OtsuMultipleThresholdsImageFilter.html). \n",
    "    - ```SetNumberOfHistogramBins ``` to 64.\n",
    "    - ```SetNumberOfThresholds ``` to 4. \n",
    "    - Make sure that this function returns the segmented image. \n",
    "    \n",
    "3. Observe the resultant segmentation using the provided function ```show_segments()```. Select the segment where the tumor is present. Since it is surrounded by unwanted components, construct a function that extracts it from the rest of the elements. To achieve this, search for the component with the highest number of pixels. Keep this image for exercise 1.2. You can visualize the filtered image by using ```show_image```.\n",
    "\n",
    "    **To create the function that selects the desired component:**\n",
    "    - Employ [```sitk.ConnectedComponentImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1ConnectedComponentImageFilter.html) to label all the components of the segmented image. Set ```SetFullyConnected()``` to True. \n",
    "    - Afterwards, use [```sitk.LabelShapeStatisticsImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LabelShapeStatisticsImageFilter.html) to compute the shape statistics over the resultant connected-components image. \n",
    "    - Utilize ```GetNumberOfLabels()``` to obtain the number of components in the image, and use ```GetNumberOfPixels()``` to get the number of pixels per component. Retrieve the element with the max number of pixels\n",
    "    - **hint:** Use ```.index()``` and ```max()``` to obtain the index of the element with the max number of pixels. Ignore the background, otherwise you will retrieve this element.\n",
    "\n",
    "4. Post-processing. Apply the following post-processing methods to the segmentation of step 4.\n",
    "    - [```sitk.BinaryFillholeImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1BinaryFillholeImageFilter.html), ```SetForegroundValue``` to 1\n",
    "    - [```sitk.BinaryDilateImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1BinaryDilateImageFilter.html), ```SetForegroundValue``` to 1, ```SetKernelRadius ``` equal to 2  and ```SetKernelType``` equal to sitk.sitkBall.\n",
    "\n",
    "5. Calcualte the DICE and Jaccard coefficient, along with the false positive error and false negative error using [```sitk.LabelOverlapMeasuresImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LabelOverlapMeasuresImageFilter.html). Additionally, calculate the Hausdorff distance employing [```sitk.HausdorffDistanceImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1HausdorffDistanceImageFilter.html). \n",
    "    - It is recommended to create a function ```evaluate()```, which takes two input arguments - binary ground truth and binary segmentation results and returns all validation criteria at once. Keep in mind that the input for the evaluation metrics should be a binary image of type ```sitk.sitkUInt8```. If your image type has to be changed, use ```sitk.Cast()``` filter.\n",
    "\n",
    "## Exercise 1.2:\n",
    "\n",
    "1. Read the images you got from exercise 1 (linear stretching) and exercise 2 (denoised) from the previous session.  If you were not able to obtain them you can find these under the folder \"MRIs266_filtered\": 'stretched.mha' and 'median_filtered.mha'.\n",
    "2. Apply the Otsu multi-thresholding algorithm to the new images and repeat the previous process to isolate the tumor from the segment where it is distinguishable. \n",
    "3. Up to now you have 3 images: (1) the tumor mask without post-processing of exercise 1.1, (2) tumor mask obtained from the linear stretched image and (3) the tumor mask obtained from the denoised image. Combine these 3 masks to obtain a better segmentation, employ a \"majority voting\" approach: \n",
    "    - Start by creating an empty 2D array with equal dimensions to one of the previous images.\n",
    "    - Iterate over each pixel position of the 3 images, average the pixel values and if this is greater than 0.5, place a 1 in the same position in the 2D array.\n",
    "4. Convert your array to a SimpleITK object using ```sitk.GetImageFromArray()```. Apply ```sitk.CopyInformation()``` to set the same metadata between your created image and the original one.\n",
    "5. Apply ```sitk.BinaryFillHoleImageFilter``` (```SetForegroundValue``` to 1) and ```sitk.BinaryDilateImageFilter``` (```SetForegroundValue``` to 1, ```SetKernelRadius ``` to 2 and ```SetKernelType``` to sitk.sitkBall.\n",
    "6. Calculate the metrics (DICE coefficient, Jaccard coefficient, false positive error, false negative error and Hausdorff distance) between the ground truth and the images from point 4 and 5.\n",
    "\n",
    "## Report\n",
    "<font color=blue>\n",
    "    \n",
    "- Plot a one-by-five image comparison of the ground truth and the four tumor segmentations: (1) Exercise 1.1 no post-processing, (2) Exercise 1.1 post-processing, (3) Exercise 1.2 majority voting no post-processing and (4) Exercise 1.2 majority voting post-processing.\n",
    "- Plot the results of each of the evaluation metric for different methods using a ```matplotlib``` barplot.\n",
    "- Discuss your results.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to show a new image which is in sitk format\n",
    "def show_image(image):\n",
    "    '''\n",
    "    This function conver a sitk image, converts it to array and shows it\n",
    "    Inputs:\n",
    "        - image: Image in SimpleITK format that will be plot\n",
    "    Outputs:\n",
    "        - A new plot\n",
    "    '''\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    plt.imshow(array, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Function to show the results of the multi-otsu threshold\n",
    "def show_segments(original_image, otsu_image):\n",
    "    '''\n",
    "    This function plots the results of the multi-threshold algorithm. Additionally, it displays the resultant \n",
    "    segments of the algorithm.\n",
    "    Inputs:\n",
    "        - original_image: The original image in sitk format.\n",
    "        - otsu_image: Image retreived from the Otsu filter in sitk format.\n",
    "    Outputs:\n",
    "        - A plot that depicts the original image, the output of the Otsu algorithm, and each of the segments\n",
    "    '''\n",
    "    # Pass images to arrays\n",
    "    original_array = sitk.GetArrayFromImage(original_image)\n",
    "    otsu_array = sitk.GetArrayFromImage(otsu_image)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(2, 3, constrained_layout=True, figsize=(12,6))\n",
    "    \n",
    "    ax[0, 0].imshow(original_array, cmap='gray')\n",
    "    ax[0, 0].set_title('Original Image')\n",
    "    ax[1, 0].imshow(otsu_array, cmap='nipy_spectral')\n",
    "    ax[1, 0].set_title('Result from Otsu')\n",
    "    ax[0, 1].imshow(otsu_array == 1, cmap='gray')\n",
    "    ax[0, 1].set_title('Segment: 1')\n",
    "    ax[0, 2].imshow(otsu_array == 2, cmap='gray')\n",
    "    ax[0, 2].set_title('Segment: 2')\n",
    "    ax[1, 1].imshow(otsu_array == 3, cmap='gray')\n",
    "    ax[1, 1].set_title('Segment: 3')\n",
    "    ax[1, 2].imshow(otsu_array == 4, cmap='gray')\n",
    "    ax[1, 2].set_title('Segment: 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Region growing\n",
    "\n",
    "Region-growing algorithms start by defining an initial region, known as a seed point, usually set by a user inside the object to be segmented. Afterwards, an iterative search is performed. In each iteration, all neighboring pixels of the seed are evaluated, and a criterion is used to determine if they should also be considered part of the object. If so, they are added to the region, and their neighbors will be evaluated in the following iteration.\n",
    "\n",
    "The criterion to add neighbors varies between applications; these could be brightness, color, texture, gradient, or geometric properties. The most common approach is to consider the intensity of the neighboring pixels. If their intensity is between lower and upper threshold values, they are included within the region. This algorithm has the benefit of considering spatial connectivity, thereby limiting the segmentation to connected regions.\n",
    "\n",
    "<img src=\"./images/region_growing.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "**(i)** Angio-MRI with seed point at the aortic arch **(ii) - (v)** Region growing from the seed point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You noticed from the previous exercises that it was impossible to directly separate the tumor from other structures, hence the need to isolate it using sitk.ConnectedComponentImageFilter(). Additionally, extra information from other modalities was required. In this exercise, you will attempt to isolate the tumor by implementing a region-growing algorithm in its simplest form.\n",
    "\n",
    "The algorithm should output a binary image with pixel values equal to 1 for the structure under study and 0 for all other pixels. It should use a seed point and two threshold values (lower and upper) as inputs.\n",
    "\n",
    "1. Start by reading the image 'Flair_0266r.mha' and the ground-truth segmentation 'Mask_0266.mha' from the folder 'MRIs266', read the ground truth as 'sitk.sitkUInt8'.\n",
    "2. Use the function ```set_seed_point()``` to visualize the image and select a seed point. Select a point in the center of the tumor.\n",
    "3. The previous function returns the coordinates of the seed point. Get the pixel intensity at the seed point. \n",
    "4. Build a function that implements a region growing algorithm. It has to compare the intensity of the seed point with the neighboring intesities. If they are within the limits, these pixels are added to the region. Evaluate the performance of the algorithm if the following threshold values are taken into account:\n",
    "\n",
    "    - Seed point intensity $\\pm$5, $\\pm$15 and $\\pm$25. \n",
    "\n",
    "5. Assess its performance by considering 4 and 8 nearest neighbors. \n",
    "\n",
    "    **To build this function:**\n",
    "    - Start from the seed point\n",
    "    - List the 4 (or 8) neighboring pixels\n",
    "    - Check if their intensity falls within the threshold boundaries. \n",
    "    - Grow your region by adding the pixels that meet the condition.\n",
    "    - List all new neighboring pixels of the obtained new region.\n",
    "    - Repeat until there are no more pixels added.\n",
    "    \n",
    "**Hint:** It may be handy to store the indexes (locations) and values of pixels which are already marked inside and those, which are currently marked as neighbors. For example: 0 - outside, 1 - inside, 2 - neighbor.\n",
    "\n",
    "5. Since you will be working with an array, make sure to convert it to a SimpleITK image and use ```sitk.CopyInformation()``` to copy the metadata from the original image.\n",
    "6. Apply ```sitk.BinaryFillholeImageFilter``` (```SetForegroundValue``` to 1) as post-processing to the resultant segmentations using the threshold of $\\pm$25. \n",
    "7. Calculate the metrics (DICE coefficient, Jaccard coefficient, false positive error, false negative error and Hausdorff distance) between the ground truth and the obtained segmentations (8 in total: 3 thresholds x 2 neighbouring strategies, and 2 post-processed images).\n",
    "\n",
    "## Report\n",
    "<font color=blue>\n",
    "    \n",
    "- Plot a two-by-five image comparison of the ground truth and the tumor segmentations at each threshold level for each number of neighbors.\n",
    "- Plot a relation (```plt.plot()```) between the number of thresholds used (x-axis) against the evaluated metric. On each figure include two plots, one for 4 neighbours and the other for 8 neighbours.\n",
    "- Discuss your results.\n",
    "- In the clinical practice, you are often faced with a trade-off between the false positive and false negative error of your segmentation (one is low, the other is high). In the case of brain tumour segmentation, would you prefer to obtain:\n",
    "    - oversegmenated volume\n",
    "    - undersegmented volume\n",
    "    - Why? Which case corresponds to what values of false positive and false negative errors?\n",
    "    \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print(matplotlib.__version__)\n",
    "    \n",
    "\n",
    "# Function to select a seed point from the image\n",
    "def set_seed_point(image):\n",
    "    '''\n",
    "    This function opens a new window and displays the image, select a point inside the tumor to set the seed point.\n",
    "    Inputs:\n",
    "        - image: Image where the seed point will be set. Format sitk.\n",
    "    Outputs:\n",
    "        - seed: 'x' and 'y' coordinates of the seed point\n",
    "    '''\n",
    "    matplotlib.use('TkAgg')\n",
    "    \n",
    "    # Pass image to array\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    # Select seed point\n",
    "    plt.figure()\n",
    "    plt.imshow(array, cmap = 'gray')\n",
    "    plt.show(block=False)\n",
    "    #User selects the intial seed point\n",
    "    print ('\\nPlease select the initial seed point')\n",
    "\n",
    "    pseed = plt.ginput(1)\n",
    "    x = int(pseed[0][0])\n",
    "    y = int(pseed[0][1])\n",
    "    seed = x, y\n",
    "\n",
    "    print ('you clicked:',seed)\n",
    "\n",
    "    # Close figure\n",
    "    plt.close('all')\n",
    "    \n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
